{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "logr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "#create datasets for model\n",
    "feature_train = bd_train.drop('Revenue Grid', axis=1)\n",
    "label_train = bd_train['Revenue Grid']\n",
    "feature_test = bd_test.drop('Revenue Grid', axis=1)\n",
    "label_test = bd_test['Revenue Grid']\n",
    "\n",
    "#Run the model\n",
    "logr.fit(feature_train, label_train)\n",
    "\n",
    "logr.predict(feature_test)\n",
    "logr.predict_proba(feature_test) #This gives probability\n",
    "logr.classes_ #This gives which probability column belongs to which prediction.\n",
    "\n",
    "#get auc score\n",
    "predicted_probs=logr.predict_proba(feature_test)[:,1]\n",
    "roc_auc_score(label_test, predicted_probs)\n",
    "\n",
    "#get the cutoff for hard classes.\n",
    "cutoffs=np.linspace(0.01,0.99,99)\n",
    "train_score=logr.predict_proba(feature_train)[:,1]\n",
    "real=label_train\n",
    "\n",
    "KS_all=[]\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    \n",
    "    predicted = (train_score>cutoff).astype(int)\n",
    "    \n",
    "    TP=((predicted==1) & (real==1)).sum()\n",
    "    TN=((predicted==0) & (real==0)).sum()\n",
    "    FP=((predicted==1) & (real==0)).sum()\n",
    "    FN=((predicted==0) & (real==1)).sum()\n",
    "    \n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    \n",
    "    KS=(TP/P)-(FP/N)\n",
    "    KS_all.append(KS)\n",
    "\n",
    "    cutoffs[KS_all==max(KS_all)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree\n",
    "#### With permutation and combinatin of the tree related parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params={ 'class_weight':[None,'balanced'], \n",
    "        'criterion':['entropy','gini'],\n",
    "        'max_depth':[None,5,10,15,20,30,50,70],\n",
    "            'min_samples_leaf':[1,2,5,10,15,20], \n",
    "            'min_samples_split':[2,5,10,15,20]\n",
    "       }\n",
    "\n",
    "clf=DecisionTreeClassifier()\n",
    "\n",
    "random_search=RandomizedSearchCV(clf,cv=10,\n",
    "                                 param_distributions=params,\n",
    "                                 scoring='roc_auc',\n",
    "                                 n_iter=10\n",
    "                                    )\n",
    "random_search.fit(x_train,y_train)\n",
    "\n",
    "dtree=random_search.best_estimator_\n",
    "\n",
    "dtree.fit(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "#### With additional ramdomness added on the feature selection, number of trees, bootstraping option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "param_dist = {\"n_estimators\":[100,200,300,500,700,1000],\n",
    "              \"max_features\": [5,10,20,25,30,35],\n",
    "              \"bootstrap\": [True, False],\n",
    "              'class_weight':[None,'balanced'], \n",
    "                'criterion':['entropy','gini'],\n",
    "                'max_depth':[None,5,10,15,20,30,50,70],\n",
    "                'min_samples_leaf':[1,2,5,10,15,20], \n",
    "                'min_samples_split':[2,5,10,15,20]\n",
    "                  }\n",
    "\n",
    "n_iter_search = 10\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search,scoring='roc_auc',cv=5)\n",
    "random_search.fit(x_train, y_train)\n",
    "random_search.best_estimator_\n",
    "\n",
    "##Report function\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.5f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "report(random_search.cv_results_,5)\n",
    "\n",
    "# select the best values from results above, they will vary slightly with each run\n",
    "rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini', max_depth=50, \n",
    "                          max_features=10, max_leaf_nodes=None, min_impurity_split=1e-07, \n",
    "                          min_samples_leaf=10, min_samples_split=20, min_weight_fraction_leaf=0.0, \n",
    "                          n_estimators=300, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "## Feature importance\n",
    "feat_imp_df=pd.DataFrame({'features':x_train.columns,'importance':rf.feature_importances_})\n",
    "feat_imp_df.sort_values('importance',ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data set ice breaker\n",
    "\n",
    "1. Check if any numeric column was supposed to be categorical and numbers are just symbolic assignment rather than representing real ordinal relationship between the categories they represent ( keep in mind to treat them as categorical )\n",
    "\n",
    "2. Check if any categorical column contains ordinal data and can be converted to numbers ( use appropriate string operations and convert to numbers )\n",
    "\n",
    "3. Check if any column has come as categorical because of some character data occurrence , but contains numeric data as such ( convert these to numeric data)\n",
    "\n",
    "4. Check if data contains missing values , and figure out how they can be imputed ( this can be different for different column, for some business logic might exist , for some simple imputation with median/avg will suffice )\n",
    "\n",
    "5. See if any columns represent perfectly duplicate information, use any one of them \n",
    "\n",
    "6. If any column contains general text data , create tfidf features \n",
    "\n",
    "7. Missing value in a categorical column should be treated as any other category \n",
    "\n",
    "_______________________________\n",
    "\n",
    "Once you have taken care of all this , check if the general patterns in the data are as per standard patterns seen in the business ( As a quick data sanity check ).\n",
    "\n",
    "For example low credit scores having higher default rate ( so mean credit score should lower for defaulters , etc ).\n",
    "\n",
    "If there is an anomaly , check with business process experts if there can be data integrity issues with what you got .\n",
    "\n",
    "For numeric columns , density plots are a quick way of sanity check in terms of usual values occurrence frequency and presence of extreme values .\n",
    "\n",
    "For categorical columns , this can be done with bar charts \n",
    "\n",
    "-------------------\n",
    "\n",
    "Many problems are not of simply predictive nature. For example , question can be what factors affect a certain outcome and how  ( without much emphasis on building a predictive model) ?\n",
    "\n",
    "You can run a quick random Forest anyway and choose top vars from variable importance plot and visualise their behaviour w.r.t. to outcome.\n",
    "\n",
    "_______________________________\n",
    "\n",
    "If you need to build a predictive model , start with knowing what is the baseline performance . This could come from couple of sources \n",
    "\n",
    "1. Minimum business expectation in terms of performance (Actionable/Viable) ...... accuracy/mae etc \n",
    "\n",
    "2. Performance of earlier best model in production \n",
    "\n",
    "Above will help you in discarding solutions which do not fit the minimum performance criterion and keep on moving towards more complex algos or data inclusions . \n",
    "\n",
    "It'll be good if you can get a tentative idea of ceiling levels for performance ( Not alway possible though ) . If you get this , it'll help you in realise when to stop ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### practise Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
